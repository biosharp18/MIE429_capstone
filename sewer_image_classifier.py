# -*- coding: utf-8 -*-
"""Sewer Image Classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nHuLYF6KRchLrNmTF7ip7xFYrg6rOCue
"""

### Classification Step - Amey + Rory

# Notes from Amey
"""
 - Lets ignore the validation data that they provided for now, just run a train-val-test
   split on a subset of the train data (pref train13.zip until we know that works, smallest)
 - Steps of ML pipeline:
    - Dataset
    - Load model
    - Loss calculation
    - training loop

"""

# pytorch lightning abstracts the training modules
# we can initialize a trainer module and avoid the need
import pandas as pd
import numpy as np
import torchvision
from torch.utils.data import Dataset
import os
from pathlib import Path
from torch.utils.data import DataLoader
import pytorch_lightning as pl
import torch
import torch.nn as nn
from pytorch_lightning import seed_everything
import wandb
from pytorch_lightning.loggers import WandbLogger
from pytorch_lightning.callbacks import ModelCheckpoint
import argparse
from torchmetrics.classification import Accuracy, BinaryPrecision, BinaryRecall

from torchvision.models import resnet18, ResNet18_Weights
from torchvision.io import read_image

class SewerMLDataset(Dataset):
    def __init__(self, data_root: Path, label_path: Path, split = "Train", transform = None):
      self.data_root = data_root
      self.file_list = os.listdir(data_root) if split=="Train" else os.listdir(data_root)[:1024]
      self.label_df = pd.read_csv(label_path)
      #Subset to 6 defect types
      self.label_df["Subset_defect"] = self.label_df["RB"]|self.label_df["IS"]|self.label_df["RO"]|self.label_df["AF"]|self.label_df["BE"]|self.label_df["FO"]
      self.transform = transform

    def __len__(self):
      return len(self.file_list)

    def __getitem__(self, idx):     # imo we should do the resizing and stuff here
      file_name = self.file_list[idx]
      file_path = os.path.join(self.data_root, file_name)
      img = read_image(file_path)
      if self.transform:
        img = self.transform(img)

      label = self.label_df[self.label_df["Filename"] == file_name]["Subset_defect"].item()

      return img, label

class ResNetModel(pl.LightningModule):
    def __init__(self, resnet_model):
        super().__init__()
        self.model = resnet_model
        num_ftrs = self.model.fc.in_features

        self.model.fc = nn.Linear(num_ftrs, 2)
        for param in self.model.parameters():
            param.requires_grad = False

        for param in self.model.fc.parameters():
            param.requires_grad = True

    def forward(self, x):
        x = self.model(x)
        # x = self.classifier(x)
        return x


class SewerMLClassifier(pl.LightningModule):   # now generic; can use with any candidate model
      def __init__(self, model, lr):
          super().__init__()
          self.model = model
          self.loss = nn.CrossEntropyLoss() # don't need softmax layer in model
          self.accuracy = Accuracy(task="binary")
          self.precision = BinaryPrecision()
          self.recall = BinaryRecall()
          self.lr = lr


      def training_step(self, batch, batch_idx):
          inputs, target = batch
          output = self.model(inputs)
          loss = self.loss(output, target.view(-1))
          self.log('train_loss', loss, on_step=True, on_epoch=False, prog_bar=True, logger=True)
          preds = torch.argmax(output, dim=1)
          # print('train_acc_step: ', self.accuracy(preds, target))
          
          self.log("train_acc", self.accuracy(preds, target), on_step=True, on_epoch=True, logger=True)
          self.log("train_pr", self.precision(preds, target), on_step=True, on_epoch=True, logger=True)
          self.log("train_rc", self.recall(preds,target), on_step=True, on_epoch=True, logger=True)
          return loss

      def validation_step(self, batch, batch_idx):
          inputs, target = batch
          output = self.model(inputs)
          loss = self.loss(output, target.view(-1))
          preds = torch.argmax(output, dim=1)
          self.log("val_loss", loss, on_step=True, on_epoch=True, logger=True)
          self.log("val_acc", self.accuracy(preds, target), on_step=True, on_epoch=True, logger=True)
          self.log("val_pr", self.precision(preds, target), on_step=True, on_epoch=True, logger=True)
          self.log("val_rc", self.recall(preds,target), on_step=True, on_epoch=True, logger=True)
          return loss

      def configure_optimizers(self):
          return torch.optim.Adam(self.model.parameters(), lr=self.lr)

def main(args):
  resnet_model = resnet18(pretrained=args.pretrained)
  seed_everything(42, workers=True)

  DATA_ROOT = Path("/scratch/ssd004/scratch/gaorory/SewerML")
  wandb_logger = WandbLogger(project="SewerML")

  #Define dataset and dataloader
  

  #Define model


  # print(resnet_model) # params check

  # Initialize the Weight Transforms
  # imo needs to go in dataset/dataloader
  weights = ResNet18_Weights.DEFAULT
  preprocess = weights.transforms()

  transforms = torch.nn.Sequential(
      preprocess,
      torchvision.transforms.RandomInvert(),
  )

  # Apply it to the input image
  # img_transformed = preprocess(img)

  print(preprocess)

  train_path = Path(DATA_ROOT / "train12")
  val_path = Path(DATA_ROOT / "train13")
  label_path = Path(DATA_ROOT / "SewerML_Train.csv")

  train_dataset = SewerMLDataset(data_root=train_path, split="Train", label_path=label_path, transform=transforms)
  val_dataset = SewerMLDataset(data_root=val_path, split="Val", label_path=label_path, transform=transforms)
  train_dataloader = DataLoader(train_dataset, batch_size=1024, shuffle=True, num_workers=3) #1024 is limit ish
  val_dataloader = DataLoader(val_dataset, batch_size=1024, shuffle=False, num_workers=3)


#Define pytorch lihgtning trainer

  checkpoint_callback = ModelCheckpoint(
      monitor="val_loss",            # Metric to monitor
      dirpath=args.checkpoint,        # Directory to save checkpoints
      filename="best-model-{epoch}-{val_loss:.2f}",    # File name template
      save_top_k=1,                  # Number of best models to save
      mode="min",                    # Minimize the monitored metric (e.g., val_loss)
      save_weights_only=False,       # Save full model (set True to save only weights)
  )
  #trainer = pl.Trainer(max_epochs=20, log_every_n_steps=1, accelerator="gpu", callbacks=[checkpoint_callback()])
  trainer = pl.Trainer(max_epochs=20, log_every_n_steps=1, accelerator="gpu", logger=wandb_logger, callbacks=[checkpoint_callback], val_check_interval=0.1)
  model = SewerMLClassifier(ResNetModel(resnet_model), lr = args.lr)
  #trainer.validate(model, val_dataloader)
  trainer.fit(model, train_dataloader, val_dataloader)

def predict_examples(dataloader, model):
  #self.model(inputs)
  batched_inputs, batched_labels = next(iter(dataloader))
  pos_examples = np.where(batched_labels==1)
  neg_examples = np.where(batched_labels==0)
  pos_preds = self.model(torch.from_numpy(batched_inputs[pos_examples, ...]))
  neg_preds = self.model(torch.from_numpy(batched_inputs[neg_examples,...]))
  plt.imshow(pos_preds[0,:,:].cpu().numpy())
  plt.imshow(neg_preds[0,:,:].cpu().numpy())
  return pos_preds

if __name__=="__main__":
  argparser = argparse.ArgumentParser()
  argparser.add_argument("--checkpoint")
  argparser.add_argument("--lr", type=float)
  argparser.add_argument("--pretrained", action="store_true")
  args = argparser.parse_args()
  main(args)
